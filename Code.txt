# Import all These

from urllib.request import urlopen,Request
from bs4 import BeautifulSoup
import requests



# Run in The next Block#


my_url="https://urdu.arynews.tv"
    url=my_url
    de=[]
    hdr={'user-agent':'Mozilla/5.0'}
    record=[]
    for year in range(2015,2016):
        Year_url=my_url+"/"+str(year)
        for month in range(1,2):
            m=month
            if m>=1 and m<=9:
                Month_url=Year_url+"/0"+str(m)
            else:
                Month_url=Year_url+"/"+str(m)
            for day in range(1,3):
                for page in range(1,3):
                    if page==1:
                        d=day 
                        if d>=1 and d<=9:
                            Day_url=Month_url+"/0"+str(d)
                            url=Day_url
                        else:
                            Day_url=Month_url+"/"+str(d)
                            url=Day_url
                    else:    
                        d=day 
                        if d>=1 and d<=9:
                            Day_url=Month_url+"/0"+str(d)+"/page/"+str(page)
                            url=Day_url
                        else:
                            Day_url=Month_url+"/"+str(d)+"/page/"+str(page)
                            url=Day_url

                    print(url)
                    rea=Request(url,headers=hdr)
                    try:
                       html=urlopen(rea)
                    except:
                          pass    
                    soup=BeautifulSoup(html)
                    for content in soup.find_all('div',class_='item-inner clearfix'):

                        Title=soup.title
                        title=Title.text
                        category=content.span.a.text
                        Headline=content.h2.a.text
                        desc=content.find('div',class_="post-summary")
                        summary=desc.text


                        link=content.find('a',class_='img-holder')
                        img=link.get('data-src')

                        link=content.find('a',class_='img-holder')
                        de.append(link.get('href'))
                        for site in de:

                            para=[]
                            hdr={'user-agent':'Mozilla/5.0'}
                            rea=Request(site,headers=hdr)
                            html=urlopen(rea)
                            soup=BeautifulSoup(html)
                            for desc in soup.findAll('div',class_="entry-content clearfix single-post-content"):
                                des=desc.find_all('p')
                                for p in des:
                                    if p not in para:                   
                                        para.append(p.text)




                        record.append((title,category,Headline,summary,img,para))
     

### Save in the DataFrame##

import pandas as pd
df=pd.DataFrame(record,columns=['Title','Category','Headline','Summary','ImgLink','Details'])
df


### Download The File From colab##


from google.colab import files
df.to_csv("2018jan24.csv",encoding='utf-8')
files.download('2018jan24.csv')   